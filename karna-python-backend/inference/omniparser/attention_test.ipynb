{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  add karna-python-backend to the path\n",
    "import sys\n",
    "sys.path.append('C:/Users/Prince/Documents/GitHub/Proejct-Karna/offline-ai-assistant/karna-python-backend')\n",
    "\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:09:44 INFO:NumExpr defaulting to 12 threads.\n",
      "01:09:44 INFO:Loading screenshot events from JSON file: C:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\data\\chatgpt\\883c46f5-c62d-4799-baa1-5e3b12f12e8c\\screenshot_events_883c46f5-c62d-4799-baa1-5e3b12f12e8c.json\n",
      "01:09:44 INFO:Loaded 4 valid mouse events with screenshots\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔══════════════════════════════════════════════════════════════════════════════╗\n",
      "║                     ATTENTION FIELD ANALYSIS: USER GUIDE                     ║\n",
      "╚══════════════════════════════════════════════════════════════════════════════╝\n",
      "\n",
      "This test visualizes how the AttentionFieldController tracks and predicts user attention\n",
      "based on mouse click sequences. Below is a guide to help you interpret the results:\n",
      "\n",
      "KEY CONCEPTS:\n",
      "------------\n",
      "• Top-Left Corner: (x, y) coordinates where the attention field begins\n",
      "• Dimensions: Width × Height of the attention field in pixels\n",
      "• Center Point: The focal point of the attention field (calculated from corner + dimensions/2)\n",
      "• Confidence Score: How certain the controller is about this attention area (0-1 scale)\n",
      "• Movement Direction: The inferred direction based on user's click patterns (UP/DOWN/LEFT/RIGHT)\n",
      "\n",
      "INTERPRETING CONSOLE OUTPUT:\n",
      "-------------------------\n",
      "For each mouse click event, you'll see:\n",
      "\n",
      "🔍 ATTENTION EVENT #N\n",
      "  Shows which event in the sequence is being analyzed\n",
      "\n",
      "⏰ Time: [timestamp]\n",
      "🖱️ Mouse Click: (x, y)\n",
      "  The exact time and position of the current mouse click\n",
      "\n",
      "📌 CURRENT ATTENTION FIELD:\n",
      "  • Top-Left Corner: (x, y)\n",
      "  • Dimensions: width × height pixels\n",
      "  • Center Point: (center_x, center_y)\n",
      "  • Confidence Score: 0.XX / 1.00\n",
      "  Details about where the system believes user attention is currently focused\n",
      "\n",
      "🔮 PREDICTED NEXT ATTENTION:\n",
      "  • Movement Direction: [DIRECTION]\n",
      "  • Top-Left Corner: (x, y)\n",
      "  • Dimensions: width × height pixels\n",
      "  • Center Point: (center_x, center_y)\n",
      "  • Prediction Confidence: 0.XX / 1.00\n",
      "  The system's prediction about where attention will move next\n",
      "\n",
      "⬇️ MOVEMENT ANALYSIS:\n",
      "  • Inferred Direction: [DIRECTION SYMBOL] [DIRECTION]\n",
      "  The system's interpretation of click movement patterns\n",
      "\n",
      "VISUALIZATION IMAGES:\n",
      "------------------\n",
      "• Red Rectangle: Current attention field\n",
      "• Blue Dashed Rectangle: Predicted next attention field\n",
      "• Red Dot: Current mouse click\n",
      "• Blue Dots: Previous mouse clicks\n",
      "• Green Arrow: Inferred movement direction\n",
      "\n",
      "CONFIDENCE SCORES:\n",
      "---------------\n",
      "• 0.70-1.00: High confidence (multiple consistent clicks)\n",
      "• 0.40-0.70: Medium confidence (limited click history)\n",
      "• <0.40: Low confidence (cold start or inconsistent clicks)\n",
      "\n",
      "The combination of detailed console output and saved visualization images provides\n",
      "a complete picture of how the attention tracking system works in real-world scenarios.\n",
      "\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "🔍 ATTENTION FIELD ANALYSIS\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "Processing 4 events in sequence...\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "🔍 ATTENTION EVENT #1\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "⏰ Time: 2025-03-29 13:17:25\n",
      "🖱️  Mouse Click: (623, 516)\n",
      "\n",
      "📌 CURRENT ATTENTION FIELD:\n",
      "  • Top-Left Corner: (523, 416)\n",
      "  • Dimensions: 200 × 200 pixels\n",
      "  • Center Point: (623, 516)\n",
      "  • Confidence Score: 0.80 / 1.00\n",
      "\n",
      "🔮 PREDICTED NEXT ATTENTION: Not available yet (need more clicks)\n",
      "\n",
      "⬇️  MOVEMENT ANALYSIS:\n",
      "  • Inferred Direction: None (not enough clicks yet)\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:09:45 INFO:Saved visualization 1/4 to attention_visualization\\attention_field_001.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "🔍 ATTENTION EVENT #2\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "⏰ Time: 2025-03-29 13:17:29\n",
      "🖱️  Mouse Click: (1320, 558)\n",
      "\n",
      "📌 CURRENT ATTENTION FIELD:\n",
      "  • Top-Left Corner: (449, 466)\n",
      "  • Dimensions: 1045 × 300 pixels\n",
      "  • Center Point: (971, 616)\n",
      "  • Confidence Score: 0.90 / 1.00\n",
      "\n",
      "🔮 PREDICTED NEXT ATTENTION:\n",
      "  • Movement Direction: RIGHT\n",
      "  • Top-Left Corner: (762, 466)\n",
      "  • Dimensions: 1045 × 300 pixels\n",
      "  • Center Point: (1284, 616)\n",
      "  • Prediction Confidence: 0.70 / 1.00\n",
      "\n",
      "⬇️  MOVEMENT ANALYSIS:\n",
      "  • Inferred Direction: ➡️ RIGHT\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:09:46 INFO:Saved visualization 2/4 to attention_visualization\\attention_field_002.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "🔍 ATTENTION EVENT #3\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "⏰ Time: 2025-03-29 13:17:57\n",
      "🖱️  Mouse Click: (956, 500)\n",
      "\n",
      "📌 CURRENT ATTENTION FIELD:\n",
      "  • Top-Left Corner: (449, 450)\n",
      "  • Dimensions: 1045 × 300 pixels\n",
      "  • Center Point: (971, 600)\n",
      "  • Confidence Score: 0.90 / 1.00\n",
      "\n",
      "🔮 PREDICTED NEXT ATTENTION:\n",
      "  • Movement Direction: LEFT\n",
      "  • Top-Left Corner: (136, 450)\n",
      "  • Dimensions: 1045 × 300 pixels\n",
      "  • Center Point: (658, 600)\n",
      "  • Prediction Confidence: 0.70 / 1.00\n",
      "\n",
      "⬇️  MOVEMENT ANALYSIS:\n",
      "  • Inferred Direction: ⬅️ LEFT\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:09:47 INFO:Saved visualization 3/4 to attention_visualization\\attention_field_003.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "🔍 ATTENTION EVENT #4\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "⏰ Time: 2025-03-29 13:18:01\n",
      "🖱️  Mouse Click: (590, 264)\n",
      "\n",
      "📌 CURRENT ATTENTION FIELD:\n",
      "  • Top-Left Corner: (408, 191)\n",
      "  • Dimensions: 1095 × 441 pixels\n",
      "  • Center Point: (955, 411)\n",
      "  • Confidence Score: 0.90 / 1.00\n",
      "\n",
      "🔮 PREDICTED NEXT ATTENTION:\n",
      "  • Movement Direction: LEFT\n",
      "  • Top-Left Corner: (80, 191)\n",
      "  • Dimensions: 1095 × 441 pixels\n",
      "  • Center Point: (627, 411)\n",
      "  • Prediction Confidence: 0.70 / 1.00\n",
      "\n",
      "⬇️  MOVEMENT ANALYSIS:\n",
      "  • Inferred Direction: ⬅️ LEFT\n",
      "────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:09:47 INFO:Saved visualization 4/4 to attention_visualization\\attention_field_004.png\n",
      "01:09:47 INFO:Completed visualization of attention fields for 4 events\n",
      "01:09:47 INFO:Output saved to directory: c:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\karna-python-backend\\inference\\omniparser\\attention_visualization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "📊 SUMMARY: Processed 4 attention events\n",
      "📁 Output saved to: c:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\karna-python-backend\\inference\\omniparser\\attention_visualization\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "Tip: Open the saved images to see visual representations of attention fields.\n",
      "     Each image shows both current attention and predicted next attention areas.\n"
     ]
    }
   ],
   "source": [
    "import inference.omniparser.test_attention_controller as test_attention_controller\n",
    "test_attention_controller.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
