{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add karna-python-backend to the path\n",
    "import sys\n",
    "sys.path.append('C:/Users/Prince/Documents/GitHub/Proejct-Karna/offline-ai-assistant/karna-python-backend')\n",
    "\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:28:53 INFO:NumExpr defaulting to 12 threads.\n",
      "11:28:57 INFO:Starting DynamicAreaDetector test...\n",
      "11:28:57 INFO:Loading data from: C:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\data\\chatgpt\\883c46f5-c62d-4799-baa1-5e3b12f12e8c\\screenshot_events_883c46f5-c62d-4799-baa1-5e3b12f12e8c.json\n",
      "11:28:57 INFO:Loading screenshot events from JSON file: C:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\data\\chatgpt\\883c46f5-c62d-4799-baa1-5e3b12f12e8c\\screenshot_events_883c46f5-c62d-4799-baa1-5e3b12f12e8c.json\n",
      "11:28:57 INFO:Loaded 4 valid mouse events with screenshots\n",
      "c:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\venv\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "11:29:07 INFO:Parsing image path: C:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\data\\chatgpt\\883c46f5-c62d-4799-baa1-5e3b12f12e8c\\screenshots\\raw\\screenshot_20250329_131725_617204.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omniparser initialized!!!\n",
      "image size: (1920, 1080)\n",
      "\n",
      "0: 736x1280 94 icons, 79.6ms\n",
      "Speed: 15.6ms preprocess, 79.6ms inference, 53.2ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "len(filtered_boxes): 101 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\venv\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:649: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "11:29:10 INFO:Created omniparser result for event_id: 9b073de5-e2c1-468f-a1ce-b7d033d4be7b\n",
      "11:29:10 INFO:Getting omniparser result model for event_id: 9b073de5-e2c1-468f-a1ce-b7d033d4be7b\n",
      "11:29:10 INFO:Converting parsed content df to bounding boxes for event_id: 9b073de5-e2c1-468f-a1ce-b7d033d4be7b\n",
      "11:29:10 INFO:Pre-processed parsed content results for event_id: 9b073de5-e2c1-468f-a1ce-b7d033d4be7b\n",
      "11:29:10 INFO:Creating omniparser result model for event_id: 9b073de5-e2c1-468f-a1ce-b7d033d4be7b\n",
      "11:29:10 INFO:Created omniparser result model for event_id: 9b073de5-e2c1-468f-a1ce-b7d033d4be7b\n",
      "11:29:10 INFO:Parsing image path: C:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\data\\chatgpt\\883c46f5-c62d-4799-baa1-5e3b12f12e8c\\screenshots\\raw\\screenshot_20250329_131729_196616.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to get parsed content: 0.7313148975372314\n",
      "image size: (1920, 1080)\n",
      "\n",
      "0: 736x1280 90 icons, 66.8ms\n",
      "Speed: 13.1ms preprocess, 66.8ms inference, 0.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "len(filtered_boxes): 97 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\venv\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:649: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "11:29:13 INFO:Created omniparser result for event_id: 2065c037-ad71-41ff-b4b7-72ad3cfbc481\n",
      "11:29:13 INFO:Getting omniparser result model for event_id: 2065c037-ad71-41ff-b4b7-72ad3cfbc481\n",
      "11:29:13 INFO:Converting parsed content df to bounding boxes for event_id: 2065c037-ad71-41ff-b4b7-72ad3cfbc481\n",
      "11:29:13 INFO:Pre-processed parsed content results for event_id: 2065c037-ad71-41ff-b4b7-72ad3cfbc481\n",
      "11:29:13 INFO:Creating omniparser result model for event_id: 2065c037-ad71-41ff-b4b7-72ad3cfbc481\n",
      "11:29:13 INFO:Created omniparser result model for event_id: 2065c037-ad71-41ff-b4b7-72ad3cfbc481\n",
      "11:29:13 INFO:Parsing image path: C:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\data\\chatgpt\\883c46f5-c62d-4799-baa1-5e3b12f12e8c\\screenshots\\raw\\screenshot_20250329_131757_316854.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to get parsed content: 0.6645467281341553\n",
      "image size: (1920, 1080)\n",
      "\n",
      "0: 736x1280 91 icons, 70.8ms\n",
      "Speed: 12.3ms preprocess, 70.8ms inference, 0.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "len(filtered_boxes): 100 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\venv\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:649: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "11:29:15 INFO:Created omniparser result for event_id: bf685989-b84d-40ba-8287-5770a19a5f0c\n",
      "11:29:15 INFO:Getting omniparser result model for event_id: bf685989-b84d-40ba-8287-5770a19a5f0c\n",
      "11:29:15 INFO:Converting parsed content df to bounding boxes for event_id: bf685989-b84d-40ba-8287-5770a19a5f0c\n",
      "11:29:15 INFO:Pre-processed parsed content results for event_id: bf685989-b84d-40ba-8287-5770a19a5f0c\n",
      "11:29:15 INFO:Creating omniparser result model for event_id: bf685989-b84d-40ba-8287-5770a19a5f0c\n",
      "11:29:15 INFO:Created omniparser result model for event_id: bf685989-b84d-40ba-8287-5770a19a5f0c\n",
      "11:29:15 INFO:Parsing image path: C:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\data\\chatgpt\\883c46f5-c62d-4799-baa1-5e3b12f12e8c\\screenshots\\raw\\screenshot_20250329_131801_573080.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to get parsed content: 0.720283031463623\n",
      "image size: (1920, 1080)\n",
      "\n",
      "0: 736x1280 91 icons, 82.9ms\n",
      "Speed: 0.0ms preprocess, 82.9ms inference, 0.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "len(filtered_boxes): 100 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\venv\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:649: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "11:29:18 INFO:Created omniparser result for event_id: 2d269a28-6aac-4484-84e7-18e7cf719987\n",
      "11:29:18 INFO:Getting omniparser result model for event_id: 2d269a28-6aac-4484-84e7-18e7cf719987\n",
      "11:29:18 INFO:Converting parsed content df to bounding boxes for event_id: 2d269a28-6aac-4484-84e7-18e7cf719987\n",
      "11:29:18 INFO:Pre-processed parsed content results for event_id: 2d269a28-6aac-4484-84e7-18e7cf719987\n",
      "11:29:18 INFO:Creating omniparser result model for event_id: 2d269a28-6aac-4484-84e7-18e7cf719987\n",
      "11:29:18 INFO:Created omniparser result model for event_id: 2d269a28-6aac-4484-84e7-18e7cf719987\n",
      "11:29:18 INFO:Completed getting omniparser result models for 4 events\n",
      "11:29:18 INFO:Successfully loaded 4 models from JSON file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to get parsed content: 0.7070260047912598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:29:18 INFO:DynamicAreaDetector initialized with similarity>=0.8, proximity<=0.1, min_persistence>=0.5\n",
      "11:29:18 INFO:Running dynamic area detection...\n",
      "11:29:18 INFO:Starting dynamic area detection for 4 frames\n",
      "11:29:18 INFO:Extracting elements from frame 0: screenshot_20250329_131725_617204.png\n",
      "11:29:19 INFO:Extracted 101 elements from frame 0\n",
      "11:29:19 INFO:Extracting elements from frame 1: screenshot_20250329_131729_196616.png\n",
      "11:29:20 INFO:Extracted 97 elements from frame 1\n",
      "11:29:20 INFO:Extracting elements from frame 2: screenshot_20250329_131757_316854.png\n",
      "11:29:20 INFO:Extracted 100 elements from frame 2\n",
      "11:29:20 INFO:Extracting elements from frame 3: screenshot_20250329_131801_573080.png\n",
      "11:29:21 INFO:Extracted 100 elements from frame 3\n",
      "11:29:21 INFO:Tracked 263 elements across 4 frames\n",
      "11:29:21 INFO:Classified 109 static and 0 dynamic elements out of 109 reliable elements\n",
      "11:29:21 WARNING:No dynamic elements found\n",
      "11:29:21 INFO:Detection Results:\n",
      "11:29:21 INFO:  largest_area: None\n",
      "11:29:21 INFO:  center_weighted: None\n",
      "C:\\Users/Prince/Documents/GitHub/Proejct-Karna/offline-ai-assistant/karna-python-backend\\inference\\omniparser\\dynamic_area_detector_test.py:98: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(fontsize=12)\n",
      "11:29:22 INFO:Saved visualization to C:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\karna-python-backend\\inference\\omniparser\\detection_output\\dynamic_area_detection.png\n",
      "11:29:22 WARNING:Test FAILED: No dynamic areas detected\n"
     ]
    }
   ],
   "source": [
    "from inference.omniparser.dynamic_area_detector_test import test_dynamic_area_detector\n",
    "\n",
    "test_dynamic_area_detector()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
