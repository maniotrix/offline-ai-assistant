{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c89d5a67-fd69-4219-a499-7dedc4792ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_helper import async_stream_vlm_generate\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572b48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_real_time_vlm_streaming():\n",
    "    \"\"\"Test real-time VLM streaming where chunks are displayed as they arrive\"\"\"\n",
    "    test_prompt = \"briefly Describe the image in 300 words\"\n",
    "    # Use notebook's directory instead of __file__\n",
    "    test_image = str(Path().resolve() / \"test.png\")\n",
    "    test_model = \"granite3.2-vision:latest\"\n",
    "    \n",
    "    print(f\"\\nTesting real-time VLM streaming with model: {test_model}\")\n",
    "    print(f\"Prompt: {test_prompt}\")\n",
    "    print(f\"Image: {test_image}\")\n",
    "    \n",
    "    try:\n",
    "        await async_stream_vlm_generate(prompt=test_prompt, image_path=test_image, model=test_model)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806bfaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing real-time VLM streaming with model: granite3.2-vision:latest\n",
      "Prompt: briefly Describe the image in 300 words\n",
      "Image: C:\\Users\\Prince\\Documents\\GitHub\\Proejct-Karna\\offline-ai-assistant\\karna-python-backend\\inference\\ollama_module\\test.png\n",
      "\n",
      "Streaming VLM response in real-time:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The image is a screenshot of a web interface that appears to be part of a job board or freelance marketplace. The layout is organized into several sections, each with its own distinct color and content. \n",
      "\n",
      "At the top, there's a navigation bar with options such as \"Dashboard,\" \"Filters,\" and \"My Interested Requests.\" Below this, there are two main columns: one on the left labeled \"Open requests\" and another on the right labeled \"Scheduled sessions.\" Each column contains several job listings, each represented by a thumbnail image, a title, a brief description, and details such as location, pay rate, and duration.\n",
      "\n",
      "The job listings include various types of freelance work, such as coding, data analysis, project management, and more. The prices for these services range from $60 to $80 per hour, with some jobs offering longer-term contracts or hourly rates. \n",
      "\n",
      "In the bottom section, there's a \"Mentor mode\" option, suggesting that users can connect with mentors or experienced professionals in their field. This section also includes job listings related to learning and teaching, such as tutoring for Azure Networking (AZ-700) and Java programming.\n",
      "\n",
      "The interface is designed to be user-friendly, with clear headings and easy-to-read text. The color scheme is consistent throughout the page, using shades of blue and white to create a calm and professional atmosphere. \n",
      "\n",
      "Overall, the image depicts a comprehensive job board that caters to both freelancers looking for work and professionals seeking mentorship or learning opportunities.\n",
      "--------------------------------------------------\n",
      "VLM Streaming complete!\n"
     ]
    }
   ],
   "source": [
    "await test_real_time_vlm_streaming()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
